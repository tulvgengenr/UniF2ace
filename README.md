# UniF²ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models

[![ArXiv](https://img.shields.io/badge/Arxiv-<2503.08120>-<COLOR>.svg)](https://arxiv.org/abs/2503.08120) [![Project](https://img.shields.io/badge/ProjectPage-UniF²ace-<COLOR>.svg)](https://tulvgengenr.github.io/UniF2ace-Project-Page/) [![Dataset](https://img.shields.io/badge/DailyPaper-HuggingFace-<COLOR>.svg)](https://huggingface.co/datasets/tulvgengenr/UniF2ace-130K)

UniF²ace is the first unified multimodal model specifically designed for face understanding and generation, encompassing tasks such as visual question answering, face image captioning and text-to-face image generation. 

![overview](assets/overview.png)

This repository contains code for the paper [UniF²ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models](https://arxiv.org/abs/2503.08120).

## News

2025.07.15 We have released the fine-grained face dataset [UniF²ace-130K](https://huggingface.co/datasets/tulvgengenr/UniF2ace-130K) with captions and VQAs !

## License

All code within this repository is under [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).
