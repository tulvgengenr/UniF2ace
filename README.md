# UniF²ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models

[![Arxiv](https://img.shields.io/badge/Arxiv-<2503.08120>-<COLOR>.svg)](https://arxiv.org/abs/2503.08120) [![Project](https://img.shields.io/badge/ProjectPage-UniF²ace-<COLOR>.svg)](https://showlab.github.io/Show-o/) [![HuggingFace](https://img.shields.io/badge/DailyPaper-HuggingFace-<COLOR>.svg)](https://huggingface.co/papers/2503.08120)

UniF²ace is the first unified multimodal model specifically designed for face understanding and generation, encompassing tasks such as visual question answering, face image captioning and text-to-face image generation. 

![overview](assets/overview.png)

This repository contains code for the paper [UniF²ace: Fine-grained Face Understanding and Generation with Unified Multimodal Models](https://arxiv.org/abs/2503.08120).

**We will release the dataset and code soon!**

## License

All code within this repository is under [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).